{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc43a09-1fbb-4bc5-9e93-23e01e04d133",
   "metadata": {},
   "source": [
    "# 4.2.6 Naive Bayes Classifier\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- [Naive Bayes Classification Algorithm](https://medium.com/aws-tip/naive-bayes-classification-algorithm-b421438c50c6)\n",
    "  \n",
    "The Naive Bayes Classifier is a probabilistic machine learning model based on Bayes' theorem. It assumes that the presence of a particular feature in a class is independent of other features. Despite this \"naive\" assumption, Naive Bayes classifiers have been found to perform well in practice, especially in text classification and spam filtering tasks. Key points include:\n",
    "\n",
    "- **Bayes' Theorem**: Naive Bayes classifiers calculate probabilities of classes based on prior probabilities and conditional probabilities of features given the class.\n",
    "- **Independence Assumption**: Features are assumed to be conditionally independent given the class label, which simplifies the computation.\n",
    "- **Types**: Common types include Gaussian Naive Bayes (for continuous features assuming a Gaussian distribution), Multinomial Naive Bayes (for discrete features, commonly used in text classification), and Bernoulli Naive Bayes (for binary features).\n",
    "- **Scalability**: Naive Bayes classifiers are computationally efficient and can scale well with large datasets and high-dimensional feature spaces.\n",
    "\n",
    "## Applications\n",
    "\n",
    "Naive Bayes classifiers are particularly suitable for:\n",
    "- **Text Classification**: Classifying documents or emails into categories based on word frequencies.\n",
    "- **Spam Detection**: Identifying spam emails based on word occurrences and patterns.\n",
    "- **Sentiment Analysis**: Analyzing sentiment in text data, such as social media posts or customer reviews.\n",
    "- **Medical Diagnosis**: Classifying medical records into disease categories based on symptoms and patient data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ecaaee-c980-4e99-9e69-6c328359260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0c90d1-a328-4980-a1f2-26b0b5e5e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be75f643-cad2-47ee-ab1d-4980ebd3b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9779991-72f7-40ca-9db5-a633233f739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes classifier (Gaussian)\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f667f9ea-a277-4d01-a99f-936803f856f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate and print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d764df-24dc-4b8d-a745-cd4b0c81a7f8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Naive Bayes classifiers are simple yet powerful probabilistic models that assume feature independence given the class label. Key points to summarize:\n",
    "\n",
    "- **Efficiency**: Naive Bayes classifiers are computationally efficient and require a small amount of training data to estimate the necessary parameters.\n",
    "- **Performance**: Despite the \"naive\" assumption of feature independence, Naive Bayes classifiers often perform well in practice, especially in text and categorical data domains.\n",
    "- **Types**: Different types of Naive Bayes classifiers (e.g., Gaussian, Multinomial, Bernoulli) are suited to different types of data distributions.\n",
    "- **Applications**: Widely used in various applications including text classification, spam filtering, sentiment analysis, and medical diagnosis.\n",
    "\n",
    "In conclusion, Naive Bayes classifiers are a versatile and effective choice for classification tasks, particularly in scenarios with categorical or text data where feature independence assumptions hold reasonably well.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
