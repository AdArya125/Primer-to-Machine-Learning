{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1a533a-fba7-449d-b084-e1ca96b38dd2",
   "metadata": {},
   "source": [
    "# 4.2.3.1 Support Vector Machines (SVM)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Support Vector Machines (SVM) are powerful supervised learning models used for classification and regression tasks. SVMs are effective in high-dimensional spaces and are particularly well-suited for scenarios where the data is not linearly separable. The key idea behind SVMs is to find the optimal hyperplane that best separates the classes in the feature space while maximizing the margin between classes. \n",
    "\n",
    "## Scenarios\n",
    "\n",
    "SVMs are particularly useful in the following scenarios:\n",
    "- **Classification**: When the classes are well-separated.\n",
    "- **Non-linear data**: SVMs can efficiently perform classification in non-linearly separable cases using kernel tricks, such as polynomial or radial basis function (RBF) kernels.\n",
    "- **High-dimensional data**: SVMs perform well even in high-dimensional spaces, such as text classification and image recognition.\n",
    "- **Outlier detection**: SVMs are effective in identifying outliers, as they focus on the support vectors closest to the decision boundary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb59077-bf90-4046-948d-04232837ebec",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "\n",
    "## Support Vector Machine - Classifier (SVC):\n",
    "- [Simplifying Support Vector Machines](https://readmedium.com/en/https:/towardsdatascience.com/support-vector-machines-svm-ml-basics-machine-learning-data-science-getting-started-1683fc99cd45)\n",
    "- [Support Vector Machines (SVM): An Intuitive Explanation](https://medium.com/low-code-for-advanced-data-science/support-vector-machines-svm-an-intuitive-explanation-b084d6238106)\n",
    "- [What is Kernel Trick in SVM ?](https://medium.com/@Suraj_Yadav/what-is-kernel-trick-in-svm-interview-questions-related-to-kernel-trick-97674401c48d)\n",
    "- [Support Vector Machines](https://medium.com/@pingsubhak/support-vector-machines-eae13985a917)\n",
    "- [Support Vector Machine (SVM), Clearly Explained!](https://python.plainenglish.io/support-vector-machine-svm-clearly-explained-d9db9123b7ac)\n",
    "- [Understanding the mathematics behind Support Vector Machines](https://shuzhanfan.github.io/2018/05/understanding-mathematics-behind-support-vector-machines/)\n",
    "- ### Youtube:\n",
    "  - [Support Vector Machine (SVM) in 2 minutes](https://www.youtube.com/watch?v=_YPScrckx28)\n",
    "  - [The Kernel Trick in Support Vector Machine (SVM)](https://www.youtube.com/watch?v=Q7vT0--5VII)\n",
    "  - [Support Vector Machines: All you need to know!](https://www.youtube.com/watch?v=ny1iZ5A8ilA)\n",
    "\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0b143-81dc-4b70-a038-b60c7b74a933",
   "metadata": {},
   "source": [
    "**Key Concepts**:\n",
    "- **Hyperplane**: The line (in 2D) or plane (in higher dimensions) that SVR uses to predict the target variable.\n",
    "- **Epsilon (Îµ)**: The margin of tolerance within which errors are tolerated. The goal is to find a hyperplane that has the maximum number of points within this epsilon margin.\n",
    "- **Support Vectors**: Data points that are closest to the hyperplane and are most informative in determining the position of the hyperplane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47ead40-ad90-4fa1-b4ff-68828d941576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75b553f-b6b7-4bc3-a4f2-626d0d4dbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427d2a5f-7599-4e9e-b08e-d0fc4eb3bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e411c039-7bd3-4b0a-a433-2b86a2afd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM classifier\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e794c7-493a-42d2-9c97-e84424aec8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report: \\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87693d1a-d297-4d39-a702-5be279035fcd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Support Vector Machines (SVM) are versatile machine learning models that excel in classification tasks, especially in scenarios where data is not linearly separable. Key points to summarize:\n",
    "\n",
    "- **Effective in Non-linear Data**: SVMs can handle complex, non-linear decision boundaries using kernel tricks.\n",
    "- **Margin Maximization**: SVMs aim to find the hyperplane that maximizes the margin between classes, promoting better generalization.\n",
    "- **Kernel Functions**: Various kernel functions (e.g., linear, polynomial, RBF) allow SVMs to capture different types of relationships in data.\n",
    "- **Applications**: Used in a wide range of applications such as text categorization, image classification, and bioinformatics.\n",
    "- **Parameter Sensitivity**: SVM performance can be sensitive to the choice of parameters like the kernel type and regularization parameter.\n",
    "\n",
    "In conclusion, Support Vector Machines are robust and effective models for classification tasks, particularly in scenarios with complex data relationships and high-dimensional feature spaces.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
