{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjLUUFozZNwv"
   },
   "source": [
    "# 8.3.3 Transformer Models\n",
    "\n",
    "## Explanation of Transformer Models\n",
    "\n",
    "Transformers are a revolutionary neural network architecture that has become foundational in Natural Language Processing (NLP). Initially introduced in the paper \"Attention is All You Need\" by Vaswani et al. in 2017, Transformers have paved the way for the development of many advanced models in NLP and other fields.\n",
    "\n",
    "## Key Components of Transformers\n",
    "\n",
    "Transformers consist of two main components: **Encoders** and **Decoders**. These components can be stacked to form various transformer architectures tailored to specific tasks.\n",
    "\n",
    "### 1. **Encoder**\n",
    "- Processes the input sequence to create context-aware representations.\n",
    "- Key layers include:\n",
    "  - **Self-Attention Mechanism**: Captures dependencies between different words in the input.\n",
    "  - **Feed-Forward Neural Network**: Further processes the context-aware representation.\n",
    "\n",
    "### 2. **Decoder**\n",
    "- Generates the output sequence, using the encoded information from the encoder.\n",
    "- Key layers include:\n",
    "  - **Self-Attention Mechanism**: Similar to the encoder but includes masking to prevent \"cheating.\"\n",
    "  - **Encoder-Decoder Attention Mechanism**: Focuses on the relevant parts of the input sequence.\n",
    "  - **Feed-Forward Neural Network**: Processes the data for output generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Readings:\n",
    "- [What is a Transformer?](https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04)\n",
    "- [Transformer Architecture explained](https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c)\n",
    "- [How Transformers Work](https://towardsdatascience.com/transformers-141e32e69591)\n",
    "- [Clear Explanation of Transformer Neural Networks](https://medium.com/@ebinbabuthomas_21082/decoding-the-enigma-a-deep-dive-into-transformer-model-architecture-749b49883628)\n",
    "- [Transformer Architecture Simplified](https://medium.com/@tech-gumptions/transformer-architecture-simplified-3fb501d461c8)\n",
    "- [What are Transformers in Artificial Intelligence?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/)\n",
    "- [NLP Course - HuggingFace](https://huggingface.co/learn/nlp-course)\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SjymiRzZit2"
   },
   "source": [
    "## Self-Attention Mechanism\n",
    "\n",
    "The self-attention mechanism allows the model to focus on different parts of the input sequence, making it possible to capture long-range dependencies.\n",
    "\n",
    "### How Self-Attention Works:\n",
    "1. **Query, Key, and Value Vectors**: Derived from the input for each word.\n",
    "2. **Attention Scores**: Determine the importance of other words relative to the current word.\n",
    "3. **Weighted Sum**: Produces a context vector that represents each word with respect to its context.\n",
    "\n",
    "## Multi-Head Attention\n",
    "\n",
    "This technique uses multiple self-attention heads in parallel, allowing the model to learn various aspects of the relationships between words simultaneously.\n",
    "\n",
    "## Positional Encoding\n",
    "\n",
    "Since transformers don't process input sequentially, positional encoding is used to inject information about the order of words in the input sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wELIUr7sZrS_"
   },
   "source": [
    "\n",
    "## Types of Transformer Models\n",
    "\n",
    "Several types of transformer models have been developed, each with unique architectures and applications:\n",
    "\n",
    "### 1. **BERT (Bidirectional Encoder Representations from Transformers)**\n",
    "- **Architecture**: Uses only the encoder part of the transformer.\n",
    "- **Training**: BERT is pre-trained on large text corpora with a masked language modeling objective, where random words in the input are masked, and the model learns to predict them.\n",
    "- **Applications**: Text classification, question answering, named entity recognition, sentiment analysis, etc.\n",
    "- **Variants**: RoBERTa (a more robust version of BERT), DistilBERT (a smaller and faster variant), and ALBERT (a lighter model with reduced parameters).\n",
    "\n",
    "### 2. **GPT (Generative Pre-trained Transformer)**\n",
    "- **Architecture**: Utilizes only the decoder part of the transformer.\n",
    "- **Training**: GPT is pre-trained on a large text corpus using a unidirectional (left-to-right) language modeling objective, where the model learns to predict the next word in a sequence.\n",
    "- **Applications**: Text generation, dialogue systems, creative writing, etc.\n",
    "- **Variants**: GPT-2 and GPT-3, which are larger models with more parameters, and GPT-4, known for even more sophisticated text generation capabilities.\n",
    "\n",
    "### 3. **T5 (Text-To-Text Transfer Transformer)**\n",
    "- **Architecture**: Uses both the encoder and decoder parts of the transformer.\n",
    "- **Training**: Converts all NLP tasks into a text-to-text format, where both the input and output are text sequences.\n",
    "- **Applications**: Multi-task learning, where tasks like translation, summarization, and classification are treated as text-to-text tasks.\n",
    "- **Variants**: T5 has different versions based on model size, such as T5-Small, T5-Base, and T5-Large.\n",
    "\n",
    "### 4. **XLNet**\n",
    "- **Architecture**: Combines the strengths of BERT and GPT by utilizing a permutation-based language modeling objective.\n",
    "- **Training**: Unlike BERT's masked language model, XLNet considers all possible permutations of the words, allowing it to capture bidirectional context while also predicting the next word.\n",
    "- **Applications**: Text classification, question answering, language modeling, etc.\n",
    "- **Variants**: XLNet has fewer versions but typically scales with model size, similar to BERT and GPT.\n",
    "\n",
    "### 5. **Transformer-XL**\n",
    "- **Architecture**: Enhances the standard transformer by introducing recurrence, which helps the model learn longer-term dependencies.\n",
    "- **Training**: Transformer-XL can maintain a memory of previous segments during training, making it more efficient for long sequences.\n",
    "- **Applications**: Language modeling, especially for long sequences where traditional transformers might struggle.\n",
    "\n",
    "### 6. **Vision Transformers (ViT)**\n",
    "- **Architecture**: Adapts the transformer model for image data, treating an image as a sequence of patches (akin to words in a sentence).\n",
    "- **Training**: Pre-trained on large datasets of images and fine-tuned for tasks like image classification.\n",
    "- **Applications**: Image classification, object detection, image segmentation.\n",
    "- **Variants**: DeiT (Data-efficient image Transformers), which is a smaller and more efficient version of ViT.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPI-g-U1ZzYO"
   },
   "source": [
    "\n",
    "## Benefits and Use Cases of Transformer Models\n",
    "\n",
    "1. **Versatility**: Transformers can be adapted for a wide range of tasks in NLP, computer vision, and even audio processing.\n",
    "  \n",
    "2. **Performance**: Transformers consistently outperform traditional models in benchmarks for tasks like translation, summarization, and question answering.\n",
    "  \n",
    "3. **Scalability**: By increasing the number of layers, heads, and parameters, transformers can be scaled to handle extremely large datasets and complex tasks.\n",
    "\n",
    "## Disadvantages of Transformers\n",
    "\n",
    "1. **Computational Cost**: Transformers require significant computational resources for both training and inference.\n",
    "  \n",
    "2. **Data Requirements**: Effective training often requires large datasets, making it challenging to apply transformers in data-scarce scenarios.\n",
    "\n",
    "## Transformer-Based Models in Use\n",
    "\n",
    "Transformers have become the backbone of many state-of-the-art models in NLP and beyond. Their architecture is flexible and powerful, allowing for various adaptations and specializations depending on the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bl-007BtZ2mZ"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BBEioH4paDqa"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9XtxBwwCapDF"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8a8e9c5005f74921b4ff598a03f8ecfa",
      "f8a802b24c06437b869bbdf811d9c660",
      "0108709998f14aec9763c8dcd894eb2f",
      "96677cb329634507b6e5c83ef0711623",
      "bdc83fa2918b412281b84adf5818a563",
      "f7628ec288014df4a967fe3314153312",
      "7cd6113d71f043f78d8d14bfad29550c",
      "302c30058825464289055ad85df71455",
      "6b8a58aabfaf4030932fe54ef63f406a",
      "0123b2e035b648a59ded86aca0e6f5b4",
      "47f74e97017f40eabd4aa26f286a7fa1"
     ]
    },
    "id": "TX8yT8vVar3p",
    "outputId": "8b3c4c22-c45e-4280-a889-12a4db417d82"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e9c5005f74921b4ff598a03f8ecfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Tokenize the dataset\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=512)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwqlkF4pauTm"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_dataset = encoded_dataset['train'].shuffle(seed=42).select(range(10000))  # Using a smaller subset for faster training\n",
    "test_dataset = encoded_dataset['test'].shuffle(seed=42).select(range(2000))  # Using a smaller subset for faster evaluation\n",
    "\n",
    "# Initialize the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g-N7NLxPa3d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the metrics\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='binary')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=2,              # Number of training epochs\n",
    "    per_device_train_batch_size=16,  # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate every epoch\n",
    "    save_strategy=\"epoch\",           # Save model every epoch\n",
    "    load_best_model_at_end=True,     # Load the best model at the end of training\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # Training arguments, defined above\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=test_dataset,           # Evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # Function to compute metrics for evaluation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "fsDwt7NIa6aO",
    "outputId": "1c354f60-5e91-467a-d2c1-2e73b4bb90d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 17:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.270237</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>0.896987</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.909808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.261713</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.921132</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.916038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.26171255111694336, 'eval_accuracy': 0.9165, 'eval_precision': 0.9211324570273003, 'eval_recall': 0.911, 'eval_f1': 0.9160382101558573, 'eval_runtime': 34.959, 'eval_samples_per_second': 57.21, 'eval_steps_per_second': 3.576, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Evaluation Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36Deo71FgU7r",
    "outputId": "14b78656-8bb6-4d3b-8eb1-c4e3fce2e1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This movie was fantastic!\n",
      "Prediction: Positive\n",
      "\n",
      "Sentence: I didn't like the film at all.\n",
      "Prediction: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Prepare new data\n",
    "sentences = [\"This movie was fantastic!\", \"I didn't like the film at all.\"]\n",
    "encodings = tokenizer(sentences, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# Move encodings to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encodings = {key: val.to(device) for key, val in encodings.items()}\n",
    "\n",
    "# Get predictions\n",
    "outputs = model(**encodings)\n",
    "predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "for sentence, prediction in zip(sentences, predictions):\n",
    "    print(f\"Sentence: {sentence}\\nPrediction: {'Positive' if prediction.item() == 1 else 'Negative'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "Mr6XYw5egjmR",
    "outputId": "37533df8-197a-4454-8a46-c2e8739a04c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[922  78]\n",
      " [ 89 911]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.92      0.92      1000\n",
      "    Positive       0.92      0.91      0.92      1000\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.92      0.92      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_dataset['label'], preds)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Classification Report\n",
    "report = classification_report(test_dataset['label'], preds, target_names=['Negative', 'Positive'])\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9jw2l-zoroX"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this section, we explored Transformer models, which have revolutionized the field of Natural Language Processing (NLP) with their ability to handle long-range dependencies and parallelize computations effectively. We examined the key concepts behind Transformer architecture, including self-attention mechanisms and positional encoding, which enable models to understand and generate human language with remarkable accuracy.\n",
    "\n",
    "We discussed several prominent Transformer models, such as BERT, GPT, and T5, highlighting their unique features and applications. BERT excels in understanding bidirectional context, GPT is known for its generative capabilities, and T5 is versatile in handling various NLP tasks through a unified framework.\n",
    "\n",
    "The implementation example demonstrated how to use the DistilBERT model for sequence classification tasks. Despite the challenges such as high computational demands and the need for proper hardware support, Transformer models continue to be at the forefront of NLP research and applications due to their superior performance and flexibility.\n",
    "\n",
    "Overall, Transformer models represent a significant advancement in machine learning and NLP, offering powerful tools for a wide range of language-related tasks.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0108709998f14aec9763c8dcd894eb2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_302c30058825464289055ad85df71455",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b8a58aabfaf4030932fe54ef63f406a",
      "value": 50000
     }
    },
    "0123b2e035b648a59ded86aca0e6f5b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "302c30058825464289055ad85df71455": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47f74e97017f40eabd4aa26f286a7fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b8a58aabfaf4030932fe54ef63f406a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7cd6113d71f043f78d8d14bfad29550c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a8e9c5005f74921b4ff598a03f8ecfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8a802b24c06437b869bbdf811d9c660",
       "IPY_MODEL_0108709998f14aec9763c8dcd894eb2f",
       "IPY_MODEL_96677cb329634507b6e5c83ef0711623"
      ],
      "layout": "IPY_MODEL_bdc83fa2918b412281b84adf5818a563"
     }
    },
    "96677cb329634507b6e5c83ef0711623": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0123b2e035b648a59ded86aca0e6f5b4",
      "placeholder": "​",
      "style": "IPY_MODEL_47f74e97017f40eabd4aa26f286a7fa1",
      "value": " 50000/50000 [00:58&lt;00:00, 918.64 examples/s]"
     }
    },
    "bdc83fa2918b412281b84adf5818a563": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7628ec288014df4a967fe3314153312": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8a802b24c06437b869bbdf811d9c660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7628ec288014df4a967fe3314153312",
      "placeholder": "​",
      "style": "IPY_MODEL_7cd6113d71f043f78d8d14bfad29550c",
      "value": "Map: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
