{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab64287-cbd7-41d6-95cc-55551cae0099",
   "metadata": {},
   "source": [
    "# 10.4.3 Q-Learning\n",
    "\n",
    "## Explanation of Q-Learning\n",
    "\n",
    "Q-Learning is a model-free reinforcement learning algorithm that aims to learn the optimal action-selection policy for a given environment. It belongs to the class of temporal difference (TD) learning methods, where the agent learns directly from the raw experiences without requiring a model of the environment. The algorithm seeks to find the best action to take in a given state by updating its Q-values, which estimate the expected future rewards for taking a specific action in a given state.\n",
    "\n",
    "The Q-value update rule is given by:\n",
    "\n",
    "$$\n",
    "Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ Q(s, a) $ is the Q-value of state $ s $ and action $ a $,\n",
    "- $ \\alpha $ is the learning rate,\n",
    "- $ r $ is the reward received after taking action $ a $,\n",
    "- $ \\gamma $ is the discount factor,\n",
    "- $ s' $ is the new state after taking action $ a $,\n",
    "- $ \\max_{a' } Q(s', a') $ is the maximum Q-value of the next state $ s' $.\n",
    "\n",
    "## Applications and Benefits of Q-Learning\n",
    "\n",
    "- **Applications:**\n",
    "  - **Game AI:** Q-Learning can be used to train agents in various games, such as tic-tac-toe, chess, or more complex games like Atari.\n",
    "  - **Robotics:** It can be applied to train robots for tasks like navigation, object manipulation, or any task requiring decision-making.\n",
    "  - **Resource Management:** Q-Learning can optimize resource allocation in network routing, energy distribution, or cloud computing.\n",
    "\n",
    "- **Benefits:**\n",
    "  - **Model-Free:** Q-Learning does not require a model of the environment, making it applicable to a wide range of problems.\n",
    "  - **Off-Policy:** Q-Learning learns the optimal policy even if the agent is following a different policy (e.g., an exploratory policy).\n",
    "  - **Simplicity:** The algorithm is relatively simple to implement and understand, making it a good starting point for learning reinforcement learning.\n",
    "\n",
    "## Methods for Implementing Q-Learning\n",
    "\n",
    "Implementing Q-Learning involves initializing the Q-values arbitrarily and iteratively updating them as the agent interacts with the environment. The agent selects actions based on an epsilon-greedy policy, which balances exploration and exploitation. The steps for implementing Q-Learning are as follows:\n",
    "\n",
    "1. **Initialize** the Q-values \\( Q(s, a) \\) arbitrarily (e.g., to zeros).\n",
    "2. **For each episode**:\n",
    "   - Initialize the state \\( s \\).\n",
    "   - **For each step** in the episode:\n",
    "     - Choose an action \\( a \\) using the epsilon-greedy policy.\n",
    "     - Take action \\( a \\), observe reward \\( r \\) and next state \\( s' \\).\n",
    "     - Update the Q-value for \\( Q(s, a) \\) using the Q-Learning update rule.\n",
    "     - Set the current state \\( s \\) to the next state \\( s' \\).\n",
    "   - Continue until the episode ends (e.g., reaching a terminal state or maximum steps).\n",
    "3. **Repeat** the process for a predefined number of episodes or until the Q-values converge.\n",
    "\n",
    "The final Q-values represent the learned policy, where the agent can select actions based on the highest Q-values for each state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc330a4-6735-466c-b5b6-1d318a3f98a0",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "### Readings:\n",
    "- [An introduction to Q-Learning: reinforcement learning](https://www.freecodecamp.org/news/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc/)\n",
    "- [Q-learning: a value-based reinforcement learning algorithm](https://medium.com/intro-to-artificial-intelligence/q-learning-a-value-based-reinforcement-learning-algorithm-272706d835cf)\n",
    "- [An introduction to Q-Learning: reinforcement learning](https://medium.com/free-code-camp/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc)\n",
    "- [Introducing Q-Learning \\( Hugging Face \\)](https://huggingface.co/learn/deep-rl-course/en/unit2/q-learning)\n",
    "- [SARSA & Q Learning in Temporal Difference for Reinforcement Learning](https://medium.com/data-science-in-your-pocket/sarsa-q-learning-in-temporal-difference-for-reinforcement-learning-with-example-8bfd902a5d2)\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e494c01-6efd-4460-9297-acda211f4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9dd59c5-099b-4b39-939e-096309c1fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the environment\n",
    "n_states = 6   # Number of states\n",
    "n_actions = 2  # Number of actions (0 = left, 1 = right)\n",
    "gamma = 0.9    # Discount factor\n",
    "alpha = 0.1    # Learning rate\n",
    "epsilon = 0.1  # Exploration rate\n",
    "n_episodes = 500  # Number of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57bd5121-030c-420a-aabc-edf126e098bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.zeros(n_states)\n",
    "rewards[-1] = 1.0  # Reward at the terminal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409bd510-e7d4-4ceb-b1b4-48ebcc9b3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = defaultdict(lambda: np.zeros(n_actions))\n",
    "\n",
    "# Epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(np.arange(n_actions))  # Explore\n",
    "    else:\n",
    "        return np.argmax(Q[state])                  # Exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bffa00d-21da-478a-9b06-3c09a3350c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning algorithm\n",
    "for episode in range(n_episodes):\n",
    "    state = np.random.randint(0, n_states - 1)  # Start from a random state\n",
    "    while state != n_states - 1:                # Loop until reaching the terminal state\n",
    "        action = choose_action(state)\n",
    "        next_state = state + 1 if action == 1 else max(0, state - 1)\n",
    "        reward = rewards[next_state]\n",
    "        best_next_action = np.argmax(Q[next_state])\n",
    "        Q[state][action] += alpha * (reward + gamma * Q[next_state][best_next_action] - Q[state][action])\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f7907a-6218-4664-90ac-966fce130f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy: [1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "optimal_policy = np.argmax([Q[state] for state in range(n_states)], axis=1)\n",
    "\n",
    "print(\"Optimal Policy:\", optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437ceeb-2329-4b55-abb6-815011150454",
   "metadata": {},
   "source": [
    "## Conclusion\r\n",
    "\r\n",
    "Q-Learning is a powerful and widely-used reinforcement learning algorithm that enables agents to learn optimal policies through interaction with the environment. By iteratively updating Q-values based on the rewards received, Q-Learning converges to an optimal policy that maximizes long-term rewards. The example provided demonstrates a simple implementation of Q-Learning in a grid world environment, highlighting the core concepts and steps involved. Understanding and applying Q-Learning is fundamental for solving various reinforcement learning tasks, making it a valuable tool in the field of AI and machine learning.\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
